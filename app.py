# SQLiteã‚’pysqlite3ã§ä¸Šæ›¸ã
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
    print("Successfully overrode sqlite3 with pysqlite3")
except ImportError:
    print("Failed to override sqlite3 with pysqlite3")

import streamlit as st
import datetime

# æœ€åˆã®Streamlitã‚³ãƒãƒ³ãƒ‰ã¨ã—ã¦ãƒšãƒ¼ã‚¸è¨­å®šã‚’è¡Œã†
st.set_page_config(page_title='ğŸ¦œğŸ”— Ask the Doc App', layout="wide")

# å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_openai import OpenAI
from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
import tempfile
import os
import pandas as pd
import io

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from components.llm import llm, oai_embeddings
from components.categories import MAJOR_CATEGORIES, MEDIUM_CATEGORIES
from components.prompts import RAG_PROMPT_TEMPLATE
from components.chat_history import ChatHistory

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'documents' not in st.session_state:
    st.session_state.documents = []
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'custom_prompts' not in st.session_state:
    st.session_state.custom_prompts = [
        {
            'name': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ',
            'content': RAG_PROMPT_TEMPLATE
        }
    ]
if 'selected_prompt' not in st.session_state:
    st.session_state.selected_prompt = 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ'

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®åˆæœŸåŒ–
vector_store = None
vector_store_available = False
chat_history = ChatHistory()

# VectorStoreã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°
def initialize_vector_store():
    global vector_store, vector_store_available
    
    # æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯å†åˆæœŸåŒ–ã—ãªã„
    if vector_store is not None:
        print("VectorStoreã¯æ—¢ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚å†åˆæœŸåŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return vector_store
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
    if 'vector_store' in st.session_state and st.session_state.vector_store is not None:
        vector_store = st.session_state.vector_store
        vector_store_available = True
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰VectorStoreã‚’å¾©å…ƒã—ã¾ã—ãŸ")
        return vector_store
        
    try:
        print("VectorStoreã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™...")
        from src.vector_store import VectorStore
        vector_store = VectorStore()
        vector_store_available = True
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.vector_store = vector_store
        print("VectorStore successfully initialized")
        return vector_store
    except Exception as e:
        vector_store_available = False
        print(f"Error initializing VectorStore: {e}")
        return None

# æœ€åˆã®1å›ã ã‘åˆæœŸåŒ–ã‚’è©¦ã¿ã‚‹
if 'vector_store_initialized' not in st.session_state:
    initialize_vector_store()
    st.session_state.vector_store_initialized = True

def register_document(uploaded_file, additional_metadata=None):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ChromaDBã«ç™»éŒ²ã™ã‚‹é–¢æ•°ã€‚
    additional_metadata: è¿½åŠ ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸
    """
    if not vector_store_available:
        st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ChromaDBãŒä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    if uploaded_file is not None:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿ - è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            content = None
            encodings_to_try = ['utf-8', 'shift_jis', 'cp932', 'euc_jp', 'iso2022_jp']
            
            file_bytes = uploaded_file.getvalue()
            
            # ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            for encoding in encodings_to_try:
                try:
                    content = file_bytes.decode(encoding)
                    st.success(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {encoding} ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    break
                except UnicodeDecodeError:
                    continue
            
            # ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ãªã‹ã£ãŸå ´åˆ
            if content is None:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚UTF-8, Shift-JIS, EUC-JP, ISO-2022-JPã®ã„ãšã‚Œã‹ã§ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
                return
            
            # ãƒ¡ãƒ¢ãƒªå†…ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=512,
                chunk_overlap=10,
                add_start_index=True,
                separators=["\n\n", "\n", "ã€‚", ".", " ", ""],
            )
            
            # åŸºæœ¬ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            base_metadata = {'source': uploaded_file.name}
            
            # è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çµ±åˆ
            if additional_metadata:
                base_metadata.update(additional_metadata)
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
            from langchain_core.documents import Document
            raw_document = Document(
                page_content=content,
                metadata=base_metadata
            )
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
            documents = text_splitter.split_documents([raw_document])

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜
            st.session_state.documents.extend(documents)

            # IDsã®ä½œæˆ
            original_ids = []
            for i, doc in enumerate(documents):
                source_ = os.path.splitext(uploaded_file.name)[0]  # æ‹¡å¼µå­ã‚’é™¤ã
                start_ = doc.metadata.get('start_index', i)
                id_str = f"{source_}_{start_:08}" #0ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦8æ¡ã«
                original_ids.append(id_str)

            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®VectorStoreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨
            global vector_store
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¿½åŠ ï¼ˆUPSERTï¼‰
            vector_store.upsert_documents(documents=documents, ids=original_ids)

            st.success(f"{uploaded_file.name} ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²ã—ã¾ã—ãŸã€‚")
            st.info(f"{len(documents)}ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            st.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç™»éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:")
            st.exception(e)

def manage_chromadb():
    """
    ChromaDBã‚’ç®¡ç†ã™ã‚‹ãƒšãƒ¼ã‚¸ã®é–¢æ•°ã€‚
    """
    st.header("ChromaDB ç®¡ç†")

    if not vector_store_available:
        st.error("ChromaDBã®æ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ç¾åœ¨ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        st.warning("ã“ã‚Œã¯SQLiteã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®éäº’æ›æ€§ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚Streamlit Cloudã§ã®å®Ÿè¡Œã«ã¯åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚")
        return

    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®vector_storeã‚’ä½¿ç”¨
    global vector_store

    # 1.ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç™»éŒ²
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader('ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„', type='txt')
    
    if uploaded_file:
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        with st.expander("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å…¥åŠ›", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                municipality = st.text_input("å¸‚åŒºç”ºæ‘å", "")
                major_category = st.selectbox(
                    "å¤§ã‚«ãƒ†ã‚´ãƒª",
                    MAJOR_CATEGORIES
                )
                medium_category = st.selectbox(
                    "ä¸­ã‚«ãƒ†ã‚´ãƒª",
                    MEDIUM_CATEGORIES.get(major_category, [])
                )
            
            with col2:
                source = st.text_input("ã‚½ãƒ¼ã‚¹å…ƒ", "")
                date_time = st.date_input("ç™»éŒ²æ—¥æ™‚", value=datetime.date.today())
                publication_date = st.date_input("ãƒ‡ãƒ¼ã‚¿å…¬é–‹æ—¥", value=None)
                latitude = st.text_input("ç·¯åº¦", "")
                longitude = st.text_input("çµŒåº¦", "")
        
        # ç™»éŒ²ãƒœã‚¿ãƒ³
        if st.button("ç™»éŒ²ã™ã‚‹"):
            with st.spinner('ç™»éŒ²ä¸­...'):
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
                metadata = {
                    "municipality": municipality,
                    "major_category": major_category,
                    "medium_category": medium_category,
                    "source": source,
                    "registration_date": str(date_time) if date_time else "",
                    "publication_date": str(publication_date) if publication_date else "",
                    "latitude": latitude,
                    "longitude": longitude,
                }
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç™»éŒ²é–¢æ•°ã‚’å‘¼ã³å‡ºã—
                register_document(uploaded_file, additional_metadata=metadata)

    st.markdown("---")

    # 2.ç™»éŒ²çŠ¶æ³ç¢ºèª
    st.subheader("ChromaDB ç™»éŒ²çŠ¶æ³ç¢ºèª")
    
    # æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    with st.expander("æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", expanded=False):
        filter_municipality = st.text_input("å¸‚åŒºç”ºæ‘åã§çµã‚Šè¾¼ã¿", "")
        filter_category = st.text_input("ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿", "")
    
    # è¡¨ç¤ºãƒœã‚¿ãƒ³
    if st.button("ç™»éŒ²æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º"):
        with st.spinner('å–å¾—ä¸­...'):
            try:
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®VectorStoreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨
                dict_data = vector_store.get_documents(ids=None)
                
                if dict_data and len(dict_data.get('ids', [])) > 0:
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    filtered_indices = range(len(dict_data['ids']))
                    
                    if filter_municipality or filter_category:
                        filtered_indices = []
                        for i, metadata in enumerate(dict_data['metadatas']):
                            municipality_match = True
                            category_match = True
                            
                            if filter_municipality and metadata.get('municipality'):
                                municipality_match = filter_municipality.lower() in metadata['municipality'].lower()
                            
                            if filter_category:
                                major_match = metadata.get('major_category') and filter_category.lower() in metadata['major_category'].lower()
                                medium_match = metadata.get('medium_category') and filter_category.lower() in metadata['medium_category'].lower()
                                category_match = major_match or medium_match
                                
                            if municipality_match and category_match:
                                filtered_indices.append(i)
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§DataFrameã‚’ä½œæˆ
                    filtered_ids = [dict_data['ids'][i] for i in filtered_indices]
                    filtered_docs = [dict_data['documents'][i] for i in filtered_indices]
                    filtered_metas = [dict_data['metadatas'][i] for i in filtered_indices]
                    
                    tmp_df = pd.DataFrame({
                        "IDs": filtered_ids,
                        "Documents": filtered_docs,
                        "å¸‚åŒºç”ºæ‘": [m.get('municipality', '') for m in filtered_metas],
                        "å¤§ã‚«ãƒ†ã‚´ãƒª": [m.get('major_category', '') for m in filtered_metas],
                        "ä¸­ã‚«ãƒ†ã‚´ãƒª": [m.get('medium_category', '') for m in filtered_metas],
                        "ã‚½ãƒ¼ã‚¹å…ƒ": [m.get('source', '') for m in filtered_metas],
                        "ç™»éŒ²æ—¥æ™‚": [m.get('registration_date', '') for m in filtered_metas],
                        "ãƒ‡ãƒ¼ã‚¿å…¬é–‹æ—¥": [m.get('publication_date', '') for m in filtered_metas],
                        "ç·¯åº¦çµŒåº¦": [f"{m.get('latitude', '')}, {m.get('longitude', '')}" for m in filtered_metas]
                    })
                    
                    st.dataframe(tmp_df)
                    st.success(f"åˆè¨ˆ {len(filtered_ids)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼ˆå…¨ {len(dict_data['ids'])} ä»¶ä¸­ï¼‰")
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç™»éŒ²ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:")
                st.exception(e)

    st.markdown("---")

    # 3.å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
    st.subheader("ChromaDB ç™»éŒ²ãƒ‡ãƒ¼ã‚¿å…¨å‰Šé™¤")
    if st.button("å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã™ã‚‹"):
        with st.spinner('å‰Šé™¤ä¸­...'):
            try:
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®VectorStoreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨
                current_ids = vector_store.get_documents(ids=None).get('ids', [])
                if current_ids:
                    vector_store.delete_documents(ids=current_ids)
                    st.success(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ {len(current_ids)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ")
                else:
                    st.info("å‰Šé™¤ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.error(f"ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:")
                st.exception(e)

def manage_prompts():
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç®¡ç†ã™ã‚‹ãƒšãƒ¼ã‚¸ã®é–¢æ•°ã€‚
    """
    st.header("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¿½åŠ 
    st.subheader("æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¿½åŠ ")
    new_prompt_name = st.text_input("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå", "")
    new_prompt_content = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹", height=300)
    
    if st.button("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ") and new_prompt_name and new_prompt_content:
        if len(st.session_state.custom_prompts) >= 3:
            st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æœ€å¤§3ã¤ã¾ã§ç™»éŒ²ã§ãã¾ã™ã€‚")
        else:
            st.session_state.custom_prompts.append({
                'name': new_prompt_name,
                'content': new_prompt_content
            })
            st.success(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ '{new_prompt_name}' ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€è¦§è¡¨ç¤ºã¨ç·¨é›†
    st.subheader("ç™»éŒ²æ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    for i, prompt in enumerate(st.session_state.custom_prompts):
        with st.expander(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt['name']}", expanded=False):
            edited_name = st.text_input("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå", prompt['name'], key=f"name_{i}")
            edited_content = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹", prompt['content'], height=300, key=f"content_{i}")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("æ›´æ–°", key=f"update_{i}"):
                    st.session_state.custom_prompts[i]['name'] = edited_name
                    st.session_state.custom_prompts[i]['content'] = edited_content
                    st.success(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ '{edited_name}' ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
            with col2:
                if st.button("å‰Šé™¤", key=f"delete_{i}") and len(st.session_state.custom_prompts) > 1:
                    st.session_state.custom_prompts.pop(i)
                    if st.session_state.selected_prompt == prompt['name']:
                        st.session_state.selected_prompt = st.session_state.custom_prompts[0]['name']
                    st.success(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ '{prompt['name']}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠ
    st.subheader("ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠ")
    prompt_names = [p['name'] for p in st.session_state.custom_prompts]
    selected_prompt = st.selectbox(
        "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„",
        prompt_names,
        index=prompt_names.index(st.session_state.selected_prompt)
    )
    st.session_state.selected_prompt = selected_prompt

# RAGã‚’ä½¿ã£ãŸLLMå›ç­”ç”Ÿæˆ
def generate_response(query_text, filter_conditions=None):
    """
    è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ã€‚
    filter_conditions: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶
    """
    if not vector_store_available:
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ããªã„ãŸã‚ã€è³ªå•ã«å›ç­”ã§ãã¾ã›ã‚“ã€‚"
    
    if query_text:
        try:
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®VectorStoreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨
            global vector_store

            # é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            selected_prompt = next(p for p in st.session_state.custom_prompts if p['name'] == st.session_state.selected_prompt)
            prompt = ChatPromptTemplate.from_template(selected_prompt['content'])

            def format_docs(docs):
                return "\n\n".join(doc.page_content for doc in docs)

            # æ¤œç´¢çµæœã‚’å–å¾—ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ãŒã‚ã‚Œã°é©ç”¨ï¼‰
            search_results = vector_store.search(query_text, n_results=5, filter_conditions=filter_conditions)
            
            # æ¤œç´¢çµæœãŒãªã„å ´åˆ
            if not search_results or not search_results.get('documents', [[]])[0]:
                return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢æ¡ä»¶ã‚’å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            
            # æ¤œç´¢çµæœã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã«å¤‰æ›
            from langchain_core.documents import Document
            docs = []
            for i, doc_text in enumerate(search_results['documents'][0]):
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                metadata = {}
                if search_results.get('metadatas') and len(search_results['metadatas']) > 0:
                    metadata = search_results['metadatas'][0][i] if i < len(search_results['metadatas'][0]) else {}
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä½œæˆ
                doc = Document(
                    page_content=doc_text,
                    metadata=metadata
                )
                docs.append(doc)

            # ä½¿ç”¨ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’è¡¨ç¤º
            st.markdown("#### æ¤œç´¢çµæœ")
            meta_info = []
            for i, doc in enumerate(docs):
                meta_str = ""
                if doc.metadata.get('municipality'):
                    meta_str += f"ã€å¸‚åŒºç”ºæ‘ã€‘{doc.metadata['municipality']} "
                if doc.metadata.get('major_category'):
                    meta_str += f"ã€å¤§ã‚«ãƒ†ã‚´ãƒªã€‘{doc.metadata['major_category']} "
                if doc.metadata.get('medium_category'):
                    meta_str += f"ã€ä¸­ã‚«ãƒ†ã‚´ãƒªã€‘{doc.metadata['medium_category']} "
                if doc.metadata.get('source'):
                    meta_str += f"ã€ã‚½ãƒ¼ã‚¹å…ƒã€‘{doc.metadata['source']}"
                
                meta_info.append(f"{i+1}. {meta_str}")
            
            st.markdown("\n".join(meta_info))

            # ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º
            st.markdown("#### ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
            st.markdown(f"**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå**: {selected_prompt['name']}")
            with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã‚’è¡¨ç¤º"):
                st.text(selected_prompt['content'])

            # ä¼šè©±å±¥æ­´ã‚’å–å¾—
            chat_history_text = chat_history.get_formatted_history()

            qa_chain = (
                {
                    "context": lambda x: format_docs(docs),
                    "chat_history": lambda x: chat_history_text,
                    "question": RunnablePassthrough(),
                }
                | prompt
                | llm
                | StrOutputParser()
            )
            return qa_chain.invoke(query_text)
        except Exception as e:
            st.error(f"è³ªå•ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:")
            st.exception(e)
            return None

def ask_question():
    """
    è³ªå•ã™ã‚‹ãƒšãƒ¼ã‚¸ã®é–¢æ•°ã€‚
    """
    st.header("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è³ªå•ã™ã‚‹")

    if not vector_store_available:
        st.error("ChromaDBã®æ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ç¾åœ¨ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
        st.warning("ã“ã‚Œã¯SQLiteã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®éäº’æ›æ€§ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ã€‚Streamlit Cloudã§ã®å®Ÿè¡Œã«ã¯åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚")
        st.info("ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®å®Ÿè¡Œã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
        return

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®è¨­å®š
    with st.expander("æ¤œç´¢ç¯„å›²ã®çµã‚Šè¾¼ã¿", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            filter_municipality = st.text_input("å¸‚åŒºç”ºæ‘å", "")
            filter_major_category = st.selectbox(
                "å¤§ã‚«ãƒ†ã‚´ãƒª",
                [""] + MAJOR_CATEGORIES
            )
        
        with col2:
            filter_medium_category = st.selectbox(
                "ä¸­ã‚«ãƒ†ã‚´ãƒª",
                [""] + (MEDIUM_CATEGORIES.get(filter_major_category, []) if filter_major_category else [])
            )
            filter_source = st.text_input("ã‚½ãƒ¼ã‚¹å…ƒ", "")

    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
    st.markdown("### ä¼šè©±å±¥æ­´")
    
    # ä¼šè©±å±¥æ­´ã®è¡¨ç¤ºã¨æ“ä½œãƒœã‚¿ãƒ³ã‚’åˆ†ã‘ã¦é…ç½®
    for message in chat_history.get_history():
        role = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if message['role'] == 'user' else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
        st.markdown(f"**{role}**: {message['content']}")
    
    # å±¥æ­´æ“ä½œãƒœã‚¿ãƒ³ã‚’æ¨ªã«é…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        # ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
        if st.button('ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢'):
            chat_history.clear_history()
            st.success("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
            st.rerun()
    
    with col2:
        # ä¼šè©±å±¥æ­´ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒœã‚¿ãƒ³
        if chat_history.get_history():
            csv_data = chat_history.get_csv_export()
            if csv_data:
                current_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_data,
                    file_name=f"ä¼šè©±å±¥æ­´_{current_time}.csv",
                    mime="text/csv",
                )

    # Query text
    query_text = st.text_input('è³ªå•ã‚’å…¥åŠ›:', 
                               placeholder='ç°¡å˜ãªæ¦‚è¦ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„')

    # è³ªå•é€ä¿¡ãƒœã‚¿ãƒ³
    if st.button('Submit') and query_text:
        with st.spinner('å›ç­”ã‚’ç”Ÿæˆä¸­...'):
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã®ä½œæˆ
            filter_conditions = {}
            if filter_municipality:
                filter_conditions["municipality"] = filter_municipality
            if filter_major_category:
                filter_conditions["major_category"] = filter_major_category
            if filter_medium_category:
                filter_conditions["medium_category"] = filter_medium_category
            if filter_source:
                filter_conditions["source"] = filter_source
                
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            chat_history.add_message('user', query_text)
            
            response = generate_response(query_text, filter_conditions)
            if response:
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                chat_history.add_message('assistant', response)
                st.success("å›ç­”:")
                st.info(response)
            else:
                st.error("å›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

def fallback_mode():
    """
    ChromaDBãŒä½¿ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
    """
    st.header("ChromaDBãŒä½¿ç”¨ã§ãã¾ã›ã‚“")
    st.error("SQLiteã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œã«ã‚ˆã‚Šã€ChromaDBã‚’ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
    st.info("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€SQLite 3.35.0ä»¥ä¸ŠãŒå¿…è¦ã§ã™ã€‚Streamlit Cloudã§ã¯ç¾åœ¨ã€SQLite 3.34.1ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    
    st.markdown("""
    ## è§£æ±ºç­–
    
    1. **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®å®Ÿè¡Œ**: 
       - ã“ã®ã‚¢ãƒ—ãƒªã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„
       - æœ€æ–°ã®SQLiteãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    
    2. **ä»£æ›¿ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**:
       - ChromaDBã®ä»£ã‚ã‚Šã«ã€ä»–ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆFAISSã€Milvusãªã©ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚æ¤œè¨ã§ãã¾ã™
    
    3. **ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ¢ãƒ¼ãƒ‰ã§ã®ä½¿ç”¨**:
       - ç¾åœ¨ã€DuckDB+Parquetãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã®å®Ÿè¡Œã‚’è©¦ã¿ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã‚‚å¤±æ•—ã—ã¦ã„ã¾ã™
       - è©³ç´°ã«ã¤ã„ã¦ã¯ã€ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    """)
    
    # æŠ€è¡“çš„ãªè©³ç´°
    with st.expander("æŠ€è¡“çš„ãªè©³ç´°"):
        st.code("""
# ã‚¨ãƒ©ãƒ¼ã®åŸå› 
ChromaDBã¯å†…éƒ¨ã§SQLite 3.35.0ä»¥ä¸Šã‚’å¿…è¦ã¨ã—ã¦ã„ã¾ã™ãŒã€
Streamlit Cloudã§ã¯ç¾åœ¨ã€SQLite 3.34.1ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

# è©¦ã¿ãŸè§£æ±ºç­–
1. pysqlite3-binaryã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
2. SQLiteã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ãƒ“ãƒ«ãƒ‰
3. DuckDB+Parquetãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ä½¿ç”¨
4. ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒã®é©ç”¨

ã„ãšã‚Œã‚‚ç’°å¢ƒåˆ¶é™ã«ã‚ˆã‚ŠæˆåŠŸã—ã¦ã„ã¾ã›ã‚“ã€‚
        """)

def main():
    """
    ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
    st.title('ğŸ¦œğŸ”— Ask the Doc App')

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    with st.sidebar:
        st.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        
        # é–‹ç™ºè€…å‘ã‘ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
            if st.button("ç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯"):
                # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèªï¼ˆAPIã‚­ãƒ¼ã¯å®‰å…¨ã®ãŸã‚ãƒã‚¹ã‚¯ï¼‰
                env_vars = {
                    "OPENAI_API_KEY": "è¨­å®šæ¸ˆã¿" if os.environ.get("OPENAI_API_KEY") else "æœªè¨­å®š",
                    "PINECONE_API_KEY": "è¨­å®šæ¸ˆã¿" if os.environ.get("PINECONE_API_KEY") else "æœªè¨­å®š",
                    "PINECONE_ENVIRONMENT": os.environ.get("PINECONE_ENVIRONMENT", "æœªè¨­å®š"),
                    "PINECONE_INDEX": os.environ.get("PINECONE_INDEX", "æœªè¨­å®š"),
                    "STREAMLIT_SESSION_ID": os.environ.get("STREAMLIT_SESSION_ID", "è‡ªå‹•ç”Ÿæˆ")
                }
                st.json(env_vars)
                
                # Pineconeã®æ¥ç¶šçŠ¶æ…‹
                st.write("#### Pineconeã®çŠ¶æ…‹")
                pinecone_status = {
                    "åˆ©ç”¨å¯èƒ½": chat_history.pinecone_available,
                    "åˆæœŸåŒ–æ¸ˆã¿": st.session_state.get("pinecone_initialized", False)
                }
                st.json(pinecone_status)
                
                # VectorStoreã®çŠ¶æ…‹
                st.write("#### VectorStoreã®çŠ¶æ…‹")
                vs_status = {
                    "åˆ©ç”¨å¯èƒ½": vector_store_available,
                    "åˆæœŸåŒ–æ¸ˆã¿": st.session_state.get("vector_store_initialized", False)
                }
                st.json(vs_status)
                
            if st.button("ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹è¡¨ç¤º"):
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®è¡¨ç¤ºï¼ˆã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãªæƒ…å ±ã¯é™¤å¤–ï¼‰
                safe_session = {k: v for k, v in st.session_state.items() 
                              if k not in ['pinecone_client', 'vector_store']}
                st.json(safe_session)

    # ChromaDBãŒä½¿ç”¨ã§ããªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰
    if not vector_store_available:
        fallback_mode()
        return

    # ãƒšãƒ¼ã‚¸é¸æŠ
    page = st.sidebar.radio("ãƒšãƒ¼ã‚¸ã‚’é¸æŠã—ã¦ãã ã•ã„", ["ChromaDB ç®¡ç†", "è³ªå•ã™ã‚‹", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†"])

    # å„ãƒšãƒ¼ã‚¸ã¸ç§»å‹•
    if page == "è³ªå•ã™ã‚‹":
        ask_question()
    elif page == "ChromaDB ç®¡ç†":
        manage_chromadb()
    elif page == "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†":
        manage_prompts()
    
    # ãƒšãƒ¼ã‚¸ãŒå¤‰æ›´ã•ã‚Œã‚‹ãŸã³ã«Pineconeã«ä¼šè©±å±¥æ­´ã‚’ä¿å­˜
    try:
        chat_history.force_save()
    except Exception as e:
        print(f"ä¼šè©±å±¥æ­´ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’ç™»éŒ²
    def save_on_exit():
        try:
            chat_history.force_save()
            print("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"çµ‚äº†æ™‚ã®ä¼šè©±å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    import atexit
    atexit.register(save_on_exit)

if __name__ == "__main__":
    main()
